% Chapter 2
\newglossaryentry{vm}{name=VM, description={Virtual Machine}}
\newglossaryentry{jpda}{name=JPDA, description={Java Platform Debugger Architecture}}
\newglossaryentry{sdk}{name=SDK, description={Software Development Kit}}
\newglossaryentry{pdb}{name=PDB, description={The Python Debugger}}
\newglossaryentry{aop}{name=AOP, description={Aspect Oriented Programming}}
\newglossaryentry{libre}{name=Libre, description={or Free software, is distributed under terms that allow users to run the software for any purpose as well as to study, change, and distribute the software and any adapted versions.}}
\newglossaryentry{jvmpi}{name=JVMPI, description={Java Virtual Machine Profiling Interface}}
\newglossaryentry{jvmti}{name=JVMTI, description={Java Virtual Machine Tools Interface}}
\newglossaryentry{smt}{name=SMT, description={Satisfiability Modulo Theories}}
\newglossaryentry{ast}{name=AST, description={Abstract Syntax Tree}}

\chapter{Related work}
\label{chap:relatedwork}
\lhead{Chapter 2. \emph{Related work}} % Write in your own chapter title to set the page header
\begin{flushright}
\textit{``Sharing is good, and with digital technology, sharing is easy.''} \\ Richard Stallman
\end{flushright}

The intention of this thesis, as brought up in the introduction, would be to implement a dynamical program analysis system. In order to meet this ambition, it is unavoidable to build a theoretical understanding of "Program Analysis" and therefore the present chapter will endeavor to do a presentation of the subject. The first part propose a definition of the field, then the second suggest some technical approaches. Following, the third section introduce some trendy analysis tools, to finally discuss the actual limitations of dynamic analysis in the fourth part.

\section{What is Program Analysis ?} 
Programming environments are an essential key for the acceptance and success of a programming language. After \cite{Ducasse1994}, without the appropriate developments and maintenance tools, programmers are likely to have a bad software understanding and therefore produce low-quality code. They will be therefore reluctant to use a language without appropriate programming environments, however powerful the programming language is.

As already introduced in the previous chapter, program analysis is an automated process which aims to analyze the behavior of a software regarding a property such as correctness, robustness, safety and liveness. Program analysis can be separated in two methods : the \gls{spa} which is performed without running the software and the \gls{dpa} which is obviously fulfilled during runtime. \citep{Wikipedi2016}

The \gls{spa} is a really simple solution because it does not require running the program for analyzing its dynamic behavior. The analysis consists in going through the source code and highlight coding errors or ensure conformance to coding guidelines. A classic example of static analysis would be a compiler which is capable of finding lexical, syntactic and even semantic mistakes. The main advantage of this method is that it allows to reason about all possible executions of a program and gives assurance about any execution, prior to deployment. 

Nevertheless, according to \cite{Gosain2015}, since the widespread use of object oriented languages, \gls{spa} is found to be ineffective. This can be explained because of the usage of run-time features like dynamic binding, polymorphism, threads etc. To remedy this situation, developers call on \gls{dpa} which can, after \cite{Marek2015100}, gain insight into the dynamics and runtime behavior of those systems during execution. Moreover, because the run-time behavior depends now on many other factors, such as program inputs, concurrency, scheduling decisions, or availability of resources, static analysis does not allow full understanding of the code. The following table, proposed by \cite{Gosain2015}, is resuming the main differences between static and dynamic analysis.

\bigskip

\begin{table}[htb]
\begin{center}
\begin{tabulary}{\textwidth}{CC}
  \hline
  Dynamic Analysis 	& Static Analysis \\\hline
  Requires program to be executed	& Does not require program to be executed \\
  More precise & Less precise \\
  Holds for a particular execution & Holds for all the executions \\
  Best suited to handle run-time programming lan- & Lacks in handling run-time programming lan-\\
guage features like polymorphism, dynamic bind & guage features.\\
ing, threads etc. &  \\
  Incurs large run-time overheads & Incurs less overheads \\\hline
\end{tabulary}
\end{center}
\caption{Comparison of Dynamic analysis with Static Analysis}
\label{list:comparaison}
\end{table}

\bigskip

In the light of this comparison, it is well worth noting that Dynamic Program Analysis does not substitute to the Static Analysis. Quite the reverse, both are interdependent tools and even if Static Program Analysis is not sufficient anymore, it still gives relevant information about the code to the programmer. The DPA should come in a second phase when the source code has been validated through SPA. As it can be surmised, the ability to examine the actual and exact run-time behavior of the program might be the DPA main advantage, whereas SPA prime edge could be the independence of input stimuli and the generalization for all executions. To illustrate these characteristics, some program analysis solutions are presented further in this chapter.

\pagebreak

\section{Program Analysis approaches}
Now that a definition of Program Analysis has been established, some different approaches are to be exposed for going into the subject in depth. Yet, since the field is expansive, the purpose of this section is not to cover the entire subject. The reading of this section should, notwithstanding, give a good overview to the reader. Here are proposed, first, the essential static analysis methods followed in a second time with the dynamic analysis techniques.

\subsection{Static methods}

The static methods are regrouped in four different categories proposed by \cite{Nielson2004} and briefly presented here, some information was also gathered from the \cite{Wikipedi2016} page which is proposing a grouping based on the same criteria.

\begin{description}
  \item[Data Flow Analysis:] is a technique which consist in gathering information about the values and their evolution at each point of the program. In the Data Flow Analysis the program is considered as a graph in which the nodes are the elementary blocks and the edges describe how control might pass from one elementary block to another.
  
  \item[Constrained Based Analysis:] or Control Flow Analysis, intent to know which functions can be called at various points during the execution ; what "elementary blocks" may lead to what other "elementary blocks".
  
  \item[Abstract Interpretation:] reside in proving that the program semantics satisfies its specification according to \cite{Cousot2008}. What the program executions actually do should satisfy what the program executions are supposed to do. It can be sumarized as a partial execution of a program which gather information about its semantics without performing all the calculations.
  
  \item[Type and Effect Systems:] are two similar techniques where the second one can be seen as an extension of the first. Type systems are using types, which are a concise, formal description of the behavior of a program fragment. \cite{Remy2017} explains that programs must behave as prescribed by their types. Hence, types must be checked and ill-typed programs must be rejected. Effect systems are, after \cite{Nielson1999}, an extension of annotated type system where the typing judgments take the form of a combination of a type and an effect. This combination is associated with a program relative to a type environment.
\end{description}


\subsection{Dynamic methods}

In the past section, some static analysis methods have been defined and therefore, the dynamic methods will are depicted here. As it was heretofore specified, dynamic analysis is a quite recent research field which status could be still defined as academical. Naturally, the different techniques are not as well established as for the static analysis and can vary a lot in accordance with the author of the different papers. For this work, the following particular methods were privileged and were already proposed by \cite{Gosain2015} in their survey of Dynamic Program Analysis Techniques and Tools. 

\begin{description}
  \item[Instrumentation based approach] needs a code instrumenter used as a pre-processor in order to inject instrumentation code into the target program. This can be done at three different stages : source code, binary code and bytecode. The first stage adds instrumentation code before the program is compiled, the second one adds it by modifying or re-writing compiled code and the last one performs tracing within the compiled code.
  
  \item[\gls{vm} Profiling based technique] uses the profiling and debugging mechanism provided by the particular virtual machine, for example the \gls{jpda} for Java \gls{sdk} or the \gls{pdb} for Python. These profilers give an insight into the inner operations of a program, especially the memory and heap usage. To capture these profiling information plug-ins are available and can access the profiling services of the VM. Benchmarks are then used for actual run-time analysis which acts like a black-box test for a program. This process involves executing or simulating the behavior of the program while collecting data which is reflecting the performance. Unfortunately this technique has the drawback of generating high run-time overheads. 
  
  \item[Aspect Oriented Programming] aims to increase modularity by allowing the separation of cross-cutting concerns. Because there is no need to add instrumentation code as the instrumentation facility is integrated within the programming language, the additional behavior is added to existing code without modifying the code itself. \gls{aop} adds the following constructs to a program : aspects, join-point, point-cuts and advices. These constructs can be considered like classes. Most popular languages have their aspect oriented extensions like AspectC++ and AspectJ. In python, there are some libraries who aims to reproduce AOP behavior but there isn't any canonical one. Actually there is a debate to what extent aspect oriented practices are useful or applicable to Python's dynamic nature. %
  
\end{description}


\section{Program Analysis tools}
This section is dedicated to the available solutions in terms of program analysis. As it will be explained in the next chapter, the proof-to-concept system will be coded in \textit{Python} and therefore an additional information will be given for solutions available in this language. As already exposed in this order, first, some Static Analysis solutions will be presented following with the dynamic method ones.

\subsection{Static Analysis tools}
Following, some of the most popular tools (commercial or free) for SPA are described, selected in widespread languages : Java, C/C++ and Python. The description are based on the official website of the tools and also on the \cite{Gomes2009} paper.

Starting with C/C++, \textbf{Splint} is a very well known tool, allowing to check for security vulnerabilities and coding mystakes. Splint is based on Lint and tries to minimize the efforts needed for its deployment. Additionally, with some annotation, Splint can extend its performances over Lint. Splint can among others detect : Dereferencing a possibly null pointer, Memory management errors including uses of dangling references and memory leaks, Problematic control flow such as likely infinite loops. \textbf{Astrée}, where as it is based on abstract interpretation, is analyzing safety-critical appli­cations written or gen­er­ated in C. It proves the absence of run-­time errors and invalid concurrent behavior for embedded applications as found in aeronautics, earth transportation, medical instrumentation, nuclear energy, and space flight. Another worth mentioning tool is the \textbf{PolySpace Verifer} tool developped by MathWorks who also created the famour Matlab software. 

Concerning Java, one recognized tool is Findbugs. With the advantage of being a \gls{libre} software, the tools uses a series of ad-hoc techniques designed to balance precision, efficiency and usability. FindBugs operates on Java bytecode, rather than source code. Another Libre software is \textbf{Checkstyle} which, as his names indicates it, allows to report any breach of standards in the source code. Finally a commercial tool, \textbf{Jtest} which is an integrated Development Testing solution, can perform Data-flow analysis Unit test-case generation and execution, static analysis, regression testing, runtime error detection, code review, and design by contract.

In the Python world, \textbf{Pylint} is a coding standard checker which follows the style recommended by the PEP 8 specification. It is also capable of detecting coding errors and is integrable in IDEs. Speaking of IDEs, \textbf{PyCharm} includes also static analysis functions like PEP8 checks, testing assistance, smart refactorings, and a host of inspections.

\subsection{Dynamic Analysis tools}

As for the static tools, the most popular DPA tools are presented here. Following, a table proposed by \cite{Gosain2015} with an summary of some available DPA tools regrouped by technique. The table indicates the concerned language and also which type of dynamic Analysis is done by the tool.
\begin{table}[htb]
\begin{center}
\begin{tabulary}{\textwidth}{L|L|L|C|C|C|C|C|C|C|C|C}
\hline
Technique             & Tool                      & Language             & \multicolumn{9}{c}{Type of Dynamic Analysis done}\\   
\hline
  & & & \rotatebox{90}{Cache Modelling} & \rotatebox{90}{Heap Allocation} & \rotatebox{90}{Buffer Overflow} & \rotatebox{90}{Memory Leak} & \rotatebox{90}{Deadlock Detection} & \rotatebox{90}{Race Detection} & \rotatebox{90}{Object LifeTime} & \rotatebox{90}{Metric Computation} & \rotatebox{90}{Invariant Detection} \\ 
\hline
                      & Daikon                    & C,C++                & & & & & & & & &\checkmark \\
                      & Valgrind                  & C,C++                & & & &\checkmark& &\checkmark& & &\\
Instr.Based           & Rational Purify           & {\tiny C, C++, Java} & & & &\checkmark& & & & & \\
                      & {\tiny Parasoft Insure++} & C,C++                & &\checkmark& &\checkmark & & & & & \\
                      & Pin                       & C                    &\checkmark & & & & & & & \\
                      & Javana                    & Java                 &\checkmark& & & & & &\checkmark & &  \\
                      & DIDUCE                    & Java                 & & & & & & & & &\checkmark  \\
\hline
AOP Based             & DJProf                    & Java                 & &\checkmark& & & & &\checkmark& & \\
                      & Racer                     & Java                 & & & & & &\checkmark& & & \\
\hline
                      & Caffeine                  & Java                 & & & & & & &\checkmark&& \\
VM Profiling          & DynaMetrics               & Java                 & & & & & & & &\checkmark& \\
Based                 & *J                        & Java                 & & & & & & & &\checkmark& \\
                      & JInsight                  & Java                 & & & &\checkmark&\checkmark& &\checkmark& & \\
\hline
\end{tabulary}
\end{center}
\caption{Dynamic Analysis Tools}
\label{list:dynamictools}
\end{table}

\textbf{Valgrind, Purify and Insure++} are instrumentation based and can automatically detect memory management and threading bugs among with profiling a program in details. While Valgrind is a instrumentation framework for building dynamic analysis tools, the two others are fully-fledged analysis software. \textbf{Javana} comes with an easy-to-use instrumentation framework so that only a few lines of instrumentation code need to be programmed for building powerful profiling tools. \textbf{Daikon} and \textbf{Diduce} are the most known tools for invariant detection and are respectively an offline and online tool. Last but not least, \textbf{Pin} is a dynamic binary instrumentation framework developed by Intel. It enables the creation of dynamic program analysis tools and can be used to observe low level events like memory references, instruction execution, and control flow as well as higher level abstractions such as procedure invocations, shared library loading, thread creation and system call execution.

For AOP based tool, the two selected programs are \textbf{DjProf} and \textbf{Racer}. The first one is a profiler used for the analysis of heap usage and object life-time analysis and the second one is a data race detector tool for concurrent programs.  

\textbf{*J} and \textbf{DynaMetrics} are two academical research projects about Virtual Machine profiling and are proposing solution for computing dynamic metrics for Java. The first one, proposed by \cite{Dufour2003}, relies on \gls{jvmpi}, while the second solution, from \cite{Singh2013}, relies on the new \gls{jvmti}. \textbf{JInsight} is for exploring run-time behaviour of Java programs visually and \textbf{Caffeine} helps to check conjectures about Java programs.

In addition to this table, some Python tools are also available even if the field seems to not to be really well developed for this programming language. That could be explainable because of the dynamic nature of the language. This might be why the following tools are developed \textit{in} Python but not \textit{for} it. The first tool is \textbf{Angr} which is a python framework for analyzing binaries. It focuses on both static and dynamic instrumentation analysis, making it applicable to a variety of tasks. \textbf{Triton} is another binaries analyzer framework and proposes python bindings. Its main components are Dynamic Symbolic Execution engine, a Taint Engine, \gls{ast} representations of the x86 and the x86-64 instructions set semantics, \gls{smt} simplification passes, an SMT Solver Interface 


\section{Dynamic Analysis limitations}

As the DPA is a quite new research field, it induce ineluctably some drawbacks and limitations. The following table created by \cite{Gosain2015} gives a good overview of the different techniques and some drawbacks.

\begin{table}[htb]
\begin{center}
\begin{tabulary}{\textwidth}{L|LLLL}
\hline
  & \multicolumn{2}{c}{Instrumentation} & VM Profiling & AOP\\
  & Static & Dynamic\\
\hline
Level of Abstraction      & Instruction/Bytecode  & Instruction/Bytecode  & Bytecode      & Programming Language\\
\hline
Overhead                  & Runtime               & Runtime               & Runtime       & Design and deployment\\
\hline
Implementation Complexity & Comparatively low     & High                  & High          & Low\\
\hline
User Expertise            & Low                   & High                  & Low           & High\\
\hline
Re-compilation            & Required              & Not Required          & Not Required  & Required\\  
\hline
\end{tabulary}
\end{center}
\caption{Dynamic Analysis Techniques comparison}
\label{list:limitations}
\end{table}

This summary shows straightforwardly some limitations of the different Dynamic Analysis techniques. Instrumentation and VM Profiling based techniques induces high Run-time overheads whereas AOP needs heavy design and deployment efforts. While the implementation complexity is rather high for Dynamic Instrumentation and VM Profiling, a strong user expertise is also needed for the first one. Finally recompilation is needed for two on four techniques.

Additionally, the programmer must be aware that the automated tools cannot guarantee the full test coverage of the source code. More over, however how powerful the tools can be, they might yet produce false positives and false negatives. This is why a human code understanding and reviewing is still an absolute necessity.

\section{Concluding remarks}

In this chapter, we tried to summaries some related work about program analysis. After defining what program analysis is, we briefly presented some of the static and dynamic approaches with their respective techniques. However, this is by no means an exhaustive presentation of all the approaches and the reader must be aware that the field is far more complex than that. 

To complete this theoretical explanations, we presented some popular tools for both approaches and spoke about some general dynamic analysis limitations. During the redaction of the chapter, it appeared clearly that the DPA field is quite recent and therefore only a few researches were conducted on the subject. 

In the next chapter, we will introduce our own contribution with  development of the proof-to-concept system.
